{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "This notebook contains analysis of data taken from the kaggle website. For background of data, visit https://www.kaggle.com/aaron7sun/stocknews. This script was mostly written as practice for myself to help get acquainted with modeling in python as I had mostly done modeling in R so far. There is another notebook that contains topic modeling using LDA for the headlines for unsupervised learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\manas'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getcwd()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We split the data set according to date '2015-01-01' as this ensures an approximately neat split between classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Users/manas/OneDrive/Documents/practice/Combined_News_DJIA.csv')\n",
    "train = data[data['Date']<'2015-01-01']\n",
    "test = data[data['Date']>'2014-12-31']"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Joining all 25 headlines for each day into one vector "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainhd = []\n",
    "for row in range(0,len(train.index)):\n",
    "    trainhd.append(''.join(str(x) for x in train.iloc[row,2:27]))\n",
    "testhd = []\n",
    "for row in range(0,len(test.index)):\n",
    "    testhd.append(''.join(str(x) for x in test.iloc[row,2:27]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 371577)\n"
     ]
    }
   ],
   "source": [
    "vectorizern2 = CountVectorizer(ngram_range = (2,2))\n",
    "trainn2 = vectorizern2.fit_transform(trainhd)\n",
    "print(trainn2.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Training a making predictions on Logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(378, 371577)\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          72  114\n",
      "1          47  145\n",
      "0.574074074074\n"
     ]
    }
   ],
   "source": [
    "logimodel = LogisticRegression()\n",
    "logimodel = logimodel.fit(trainn2, train['Label'])\n",
    "testn2 = vectorizern2.transform(testhd)\n",
    "print(testn2.shape)\n",
    "testpred = logimodel.predict(testn2)\n",
    "print(pd.crosstab(test[\"Label\"],testpred, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(logimodel.score(testn2, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Looking at words with most negative scores as these would have higher contribution towards the stock dropping that day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Coefficient            Words\n",
      "119549    -0.209019          fire on\n",
      "49189     -0.209340        bin laden\n",
      "156179    -0.211252            if he\n",
      "222388    -0.214659  nuclear weapons\n",
      "667       -0.219754           10 000\n",
      "32005     -0.221851       around the\n",
      "345236    -0.223192            up in\n",
      "325492    -0.224133         there is\n",
      "331498    -0.224201          to kill\n",
      "319269    -0.318302      the country\n"
     ]
    }
   ],
   "source": [
    "wordsn2 = vectorizern2.get_feature_names()\n",
    "coeffsn2 = logimodel.coef_.tolist()[0]\n",
    "coeffdf = pd.DataFrame({'Words' : wordsn2, \n",
    "                        'Coefficient' : coeffsn2})\n",
    "coeffdf = coeffdf.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "print(coeffdf.tail(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Next we try the Tfidf vectorizer which looks at word frequencies rather than word counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 615)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=0.03, max_df=0.97, max_features = 200000, ngram_range = (2, 2))\n",
    "tfidftrain = tfidf.fit_transform(trainhd)\n",
    "print(tfidftrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          77  109\n",
      "1          53  139\n",
      "0.571428571429\n"
     ]
    }
   ],
   "source": [
    "tflogimodel = logimodel.fit(tfidftrain, train['Label'])\n",
    "tfidftest = tfidf.transform(testhd)\n",
    "testpredtfidf = logimodel.predict(tfidftest)\n",
    "print(pd.crosstab(test[\"Label\"],testpredtfidf, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(tflogimodel.score(tfidftest, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Coefficient            Words\n",
      "63     -0.949706    been arrested\n",
      "594    -0.955817          why the\n",
      "525    -0.998790          to kill\n",
      "83     -1.034238      children in\n",
      "123    -1.118211          fire on\n",
      "558    -1.122707            up in\n",
      "36     -1.164176       around the\n",
      "1      -1.180613           10 000\n",
      "292    -1.215791  nuclear weapons\n",
      "420    -1.330145      the country\n"
     ]
    }
   ],
   "source": [
    "wordstf = tfidf.get_feature_names()\n",
    "coeffstf = tflogimodel.coef_.tolist()[0]\n",
    "coeffdf1 = pd.DataFrame({'Words' : wordstf, \n",
    "                        'Coefficient' : coeffstf})\n",
    "coeffdf1 = coeffdf1.sort_values(['Coefficient', 'Words'], ascending=[0, 1])\n",
    "print(coeffdf1.tail(10))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "NBmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          43  143\n",
      "1          53  139\n",
      "0.481481481481\n"
     ]
    }
   ],
   "source": [
    "nbmodel = MultinomialNB(alpha = 0.01)\n",
    "nbmodeln2 = nbmodel.fit(trainn2, train[\"Label\"])\n",
    "nbpredn2 = nbmodeln2.predict(testn2)\n",
    "print(pd.crosstab(test[\"Label\"], nbpredn2, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(nbmodeln2.score(testn2, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          44  142\n",
      "1          23  169\n",
      "0.563492063492\n"
     ]
    }
   ],
   "source": [
    "nbmodeltf = nbmodel.fit(tfidftrain, train[\"Label\"])\n",
    "nbpredtf = nbmodeltf.predict(tfidftest)\n",
    "print(pd.crosstab(test[\"Label\"], nbpredtf, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(nbmodel.score(tfidftest, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          41  145\n",
      "1          49  143\n",
      "0.486772486772\n"
     ]
    }
   ],
   "source": [
    "rfmod = RandomForestClassifier(n_estimators=100, min_samples_leaf = 10, max_features = 0.3,\n",
    "                                oob_score = True)\n",
    "rfmodn2 = rfmod.fit(trainn2, train[\"Label\"])\n",
    "rfn2pred = rfmodn2.predict(testn2)\n",
    "print(pd.crosstab(test[\"Label\"],rfn2pred, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(rfmodn2.score(testn2, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   0    1\n",
      "Actual            \n",
      "0          58  128\n",
      "1          52  140\n",
      "0.52380952381\n"
     ]
    }
   ],
   "source": [
    "rfmodtf = rfmod.fit(tfidftrain, train[\"Label\"])\n",
    "rftfpred = rfmodtf.predict(tfidftest)\n",
    "print(pd.crosstab(test[\"Label\"],rftfpred, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(rfmodtf.score(tfidftest, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Since models like Random Forests have many parameters, I have used a pipeline along with a grid search to determine the best parameters. I've used accuracy as the measure that was used to pick the best model. But we can use AUC or any other metric according to our needs. Since Tfidf seems to perform better than count, that has been taken. As we can see, accuracy has increased in  both random forest and Naive Bayes. Note: Grid Search takes a long time to run, so make sure you have a competent processor and enough memory before running the code below.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfvect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.7, max_features=200000, min_df=0.03,\n",
      "        ngram_range=(2, 2), norm='l2', preprocessor=None, smooth_idf=T...timators=50, n_jobs=-1,\n",
      "            oob_score=False, random_state=42, verbose=0, warm_start=False))])\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          62  124\n",
      "1          50  142\n"
     ]
    }
   ],
   "source": [
    "tfvect = TfidfVectorizer(ngram_range = (2,2), max_features = 200000)\n",
    "rf = RandomForestClassifier(n_jobs = -1, random_state = 42)\n",
    "pipe = Pipeline(steps = [('tfvect',tfvect),('rf', rf)])\n",
    "parameters = {'tfvect__max_df' : [0.7,0.2, 0.97], 'tfvect__min_df' : [0.03,0.04], \n",
    "              'rf__n_estimators' : [10,50,100], 'rf__min_samples_leaf' : [1,2,5,10],\n",
    "              'rf__max_features' : ['auto', 0.3,0.4]}\n",
    "g_search = GridSearchCV(pipe, parameters, scoring = 'accuracy')\n",
    "g_fit = g_search.fit(trainhd, train[\"Label\"])\n",
    "best_est = g_fit.best_estimator_\n",
    "print(best_est)\n",
    "best_pred = g_fit.predict(testhd)\n",
    "print(pd.crosstab(test[\"Label\"],best_pred, rownames = [\"Actual\"], colnames = [\"Predicted\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539682539683\n"
     ]
    }
   ],
   "source": [
    "print(best_est.score(testhd, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "     steps=[('tfvect', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.3, max_features=200000, min_df=0.03,\n",
      "        ngram_range=(2, 2), norm='l2', preprocessor=None, smooth_idf=T...rue,\n",
      "        vocabulary=None)), ('nb', MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True))])\n",
      "Predicted   0    1\n",
      "Actual            \n",
      "0          47  139\n",
      "1          25  167\n",
      "0.566137566138\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "pipe1 = Pipeline(steps = [('tfvect',tfvect),('nb', nb)])\n",
    "parameters1 = {'tfvect__max_df' : [0.7, 0.97, 0.2, 0.3], 'tfvect__min_df' : [0.02, 0.03, 0.04], \n",
    "              'nb__alpha':[0.01,0.1, 0.001], 'nb__fit_prior': [True]}\n",
    "g_search1 = GridSearchCV(pipe1, parameters1, scoring = 'accuracy')\n",
    "g_fit1 = g_search1.fit(trainhd, train[\"Label\"])\n",
    "best_est1 = g_fit1.best_estimator_\n",
    "print(best_est1)\n",
    "best_pred1 = g_fit1.predict(testhd)\n",
    "print(pd.crosstab(test[\"Label\"],best_pred1, rownames = [\"Actual\"], colnames = [\"Predicted\"]))\n",
    "print(best_est1.score(testhd, test[\"Label\"]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "I hope this notebook was useful to you. Further things that can be done with the data: \n",
    "\n",
    "1. Try using data from previous days to predict current day's stock movement (will need a lot more processing power and better optimization techniques).  \n",
    "2. Try models like SVM as they tend to give good results in text classification problems.\n",
    "3. Try some optimization to increase efficiency of current code. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
